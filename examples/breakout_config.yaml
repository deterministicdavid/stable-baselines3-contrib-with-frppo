# config.yaml
# Configuration for PPO CarRacing training

# --- General Env ---
env_name: "ALE/Breakout-v5"
n_stack: 4

# --- Training Parameters ---
train:
  algo: "PPO"
  n_envs: 12 # Default number of parallel environments
  n_steps: 1024 #Â number of steps to do in an environment
  batch_size: 1024
  total_timesteps: 20000000
  fr_tau_penalty: 0.00001
  ent_coef: 0.1

# --- Logging & Saving ---
logging:
  log_dir: "./logs_breakout/"
  name_prefix: "ppo_breakout_latest"
  checkpoint_save_freq: 10000 # OverwriteCheckpointCallback save frequency

# --- Visualization ---
visualize:
  video_folder: "videos_breakout/"
  deterministic: false
